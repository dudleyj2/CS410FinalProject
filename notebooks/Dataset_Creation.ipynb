{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reddit Discussion Recommender Bot\n",
    "## Dataset Creation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In general usage, this Reddit recommender system is centered around the concept of finding *ongoing* discussions that are similar to selected discussion.\n",
    "This involves an ongoing and real-time collection and creation of the dataset.\n",
    "\n",
    "Furthermore, for the recommendation to work well, it is helpful to have a reasonably large dataset.  In practice, this means collecting comments for an hour or more.\n",
    "\n",
    "For the purposes of testing and demonstration, it may prove rather helpful to have somewhat a contrived dataset.\n",
    "\n",
    "We have created one or more mocked up Reddit discussions.\n",
    "\n",
    "Here we'll created a corresponding dataset.\n",
    "\n",
    "This should help to demonstrate some of the components of the recommender system."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import whoosh\n",
    "import psaw\n",
    "\n",
    "from whoosh.fields import Schema, TEXT, ID, STORED\n",
    "from whoosh.analysis import StemmingAnalyzer, RegexTokenizer, LowercaseFilter, StopFilter, StemFilter\n",
    "import os, os.path\n",
    "from whoosh import index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": false
   },
   "source": [
    "## Create the Index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to create the index and prepare it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the Analyzer\n",
    "\n",
    "The analyzer in Whoosh is analagous to the filter chain in MeTA.\n",
    "\n",
    "This analyzer is relatively simple.  It does the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "analyzer = RegexTokenizer() | LowercaseFilter() | StopFilter() | StemFilter()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the Schema\n",
    "\n",
    "The schema in Whoosh is describes how things are stored in the (inverted) index.\n",
    "\n",
    "Several fields can be stored in the index.  Fields can be stored in the index, analagous to a postings file.\n",
    "\n",
    "In this case, we don't need the actual documents (comment text body) stored.  We need that indexed.\n",
    "\n",
    "But we do need the several other pieces of data about the comment stored so we can use them later to create the recommendation after analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "schema = Schema(\n",
    "    comment_id=ID(stored=True),\n",
    "    parent_id=ID(stored=True),\n",
    "    submission_id=ID(stored=True),\n",
    "    subreddit_id=ID(stored=True),\n",
    "    content=TEXT(analyzer=analyzer)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initiate the Index\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_dir = \"../data/processed\"\n",
    "if not os.path.exists(index_dir):\n",
    "    os.mkdir(index_dir)\n",
    "else:\n",
    "    # Do I need to do anything to clean up?\n",
    "    # No... it will clean things up once we write the first comment\n",
    "    pass\n",
    "ix = index.create_in(index_dir, schema)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Populate the Index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In normal usage, the recommender system uses the psaw interface to Pushshift.io to ingest comments on an ongoing fashion.\n",
    "\n",
    "Here, we'll change the way we use PSAW.\n",
    "\n",
    "Our primary goal here will be to slurp up identified submissions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_list = [\n",
    "    # https://www.reddit.com/r/askscience/comments/bpf6mx/earth_has_seasons_because_our_planets_axis_of/\n",
    "    'bpf6mx',\n",
    "    # https://www.reddit.com/r/explainlikeimfive/comments/4ajypn/eli5why_does_earth_axial_tilt_dictate_seasons_but/\n",
    "    '4ajypn',\n",
    "    # https://www.reddit.com/r/askscience/comments/3wooz2/how_common_are_planets_with_tilts_like_ours_are/\n",
    "    '3wooz2',\n",
    "    # https://www.reddit.com/r/OutOfTheLoop/comments/4xzwwv/what_is_3d_chess/\n",
    "    '4xzwwv'\n",
    "    # https://www.reddit.com/r/DaystromInstitute/comments/8n48s6/how_do_you_play_threedimensional_chess/\n",
    "    '8n48s6'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['bpf6mx']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get the api to Pushshift.io"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "api = psaw.PushshiftAPI()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First... an example\n",
    "Before we stuff things into the inverted index, let's take a look at what we get from psaw.\n",
    "\n",
    "Here we query on the submission id.  We can sort the results.  But more importantly we filter the query\n",
    "to ensure we only get the fields we require.\n",
    "\n",
    "I know this first submission (at last at the moment I'm typing this) only has a couple comments..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "comment(body=\"There's a range of axial tilts [within the solar system](https://en.wikipedia.org/wiki/Axial_tilt#Solar_System_bodies). There has been [some work](https://phys.org/news/2012-01-loss-planetary-tilt-doom-alien.html) suggesting that no axial tilt would result in an inhospitable planet with the tropics too hot and the poles too cold. Conversely, too tipped may result in most of the planet having 6 months of light and 6 months of dark, which again falls into extremes that may be inhospitable.\", created_utc=1558077470, id='envjb1h', link_id='t3_bpf6mx', parent_id='t3_bpf6mx', permalink='/r/askscience/comments/bpf6mx/earth_has_seasons_because_our_planets_axis_of/envjb1h/', subreddit_id='t5_2qm4e', created=1558099070.0, d_={'body': \"There's a range of axial tilts [within the solar system](https://en.wikipedia.org/wiki/Axial_tilt#Solar_System_bodies). There has been [some work](https://phys.org/news/2012-01-loss-planetary-tilt-doom-alien.html) suggesting that no axial tilt would result in an inhospitable planet with the tropics too hot and the poles too cold. Conversely, too tipped may result in most of the planet having 6 months of light and 6 months of dark, which again falls into extremes that may be inhospitable.\", 'created_utc': 1558077470, 'id': 'envjb1h', 'link_id': 't3_bpf6mx', 'parent_id': 't3_bpf6mx', 'permalink': '/r/askscience/comments/bpf6mx/earth_has_seasons_because_our_planets_axis_of/envjb1h/', 'subreddit_id': 't5_2qm4e', 'created': 1558099070.0})\n",
      "comment(body='You should keep in mind that near the equator there are basically no seasons. Between the tropical circles of latitude, the sun moves slightly away from zenith over the course of the year, but never enough to cause seasons as in regions further north or south. Rain forests have the largest biodiversity and they all lie in this always-summer region. Humans also first appeared at these latitudes. So you could just as well argue that seasons are actually hindering the evolution of life (probably since they enforce more environmental adaption).', created_utc=1558089212, id='enw2wz6', link_id='t3_bpf6mx', parent_id='t3_bpf6mx', permalink='/r/askscience/comments/bpf6mx/earth_has_seasons_because_our_planets_axis_of/enw2wz6/', subreddit_id='t5_2qm4e', created=1558110812.0, d_={'body': 'You should keep in mind that near the equator there are basically no seasons. Between the tropical circles of latitude, the sun moves slightly away from zenith over the course of the year, but never enough to cause seasons as in regions further north or south. Rain forests have the largest biodiversity and they all lie in this always-summer region. Humans also first appeared at these latitudes. So you could just as well argue that seasons are actually hindering the evolution of life (probably since they enforce more environmental adaption).', 'created_utc': 1558089212, 'id': 'enw2wz6', 'link_id': 't3_bpf6mx', 'parent_id': 't3_bpf6mx', 'permalink': '/r/askscience/comments/bpf6mx/earth_has_seasons_because_our_planets_axis_of/enw2wz6/', 'subreddit_id': 't5_2qm4e', 'created': 1558110812.0})\n"
     ]
    }
   ],
   "source": [
    "for submission_id in submission_list[:1]:\n",
    "    results = api.search_comments(\n",
    "        link_id = submission_id,\n",
    "        sort='asc',\n",
    "        sort_type='created_utc',\n",
    "        filter=['id','parent_id','link_id','subreddit_id', 'body','permalink']\n",
    "    )\n",
    "    results = list(results)\n",
    "    for comment in results:\n",
    "        print(comment)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now... let's see what happens to our comment text via our analyzer..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['hello', 'there', 'test']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[token.text for token in analyzer(\"Hello there, this is a TEST\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['there',\n",
       " 'rang',\n",
       " 'axial',\n",
       " 'tilt',\n",
       " 'within',\n",
       " 'solar',\n",
       " 'system',\n",
       " 'http',\n",
       " 'en.wikipedia.org',\n",
       " 'wiki',\n",
       " 'axial_tilt',\n",
       " 'solar_system_bodi',\n",
       " 'there',\n",
       " 'ha',\n",
       " 'been',\n",
       " 'some',\n",
       " 'work',\n",
       " 'http',\n",
       " 'phys.org',\n",
       " 'new',\n",
       " '2012',\n",
       " '01',\n",
       " 'loss',\n",
       " 'planetari',\n",
       " 'tilt',\n",
       " 'doom',\n",
       " 'alien.html',\n",
       " 'suggest',\n",
       " 'no',\n",
       " 'axial',\n",
       " 'tilt',\n",
       " 'would',\n",
       " 'result',\n",
       " 'inhospit',\n",
       " 'planet',\n",
       " 'tropic',\n",
       " 'too',\n",
       " 'hot',\n",
       " 'pole',\n",
       " 'too',\n",
       " 'cold',\n",
       " 'convers',\n",
       " 'too',\n",
       " 'tipp',\n",
       " 'result',\n",
       " 'most',\n",
       " 'planet',\n",
       " 'have',\n",
       " 'month',\n",
       " 'light',\n",
       " 'month',\n",
       " 'dark',\n",
       " 'which',\n",
       " 'again',\n",
       " 'fall',\n",
       " 'into',\n",
       " 'extrem',\n",
       " 'inhospit']"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[token.text for token in analyzer(results[0].body)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Populate the index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "with ix.writer() as writer:\n",
    "    for submission_id in submission_list:\n",
    "        results = api.search_comments(\n",
    "            link_id = submission_id,\n",
    "            sort='asc',\n",
    "            sort_type='created_utc',\n",
    "            filter=['id','parent_id','link_id','subreddit_id', 'body','permalink']\n",
    "        )\n",
    "        for comment in results:\n",
    "            writer.add_document(\n",
    "                comment_id = comment.id,\n",
    "                parent_id = comment.parent_id,\n",
    "                submission_id = comment.link_id,\n",
    "                subreddit_id = comment.subreddit_id,\n",
    "                content = comment.body\n",
    "            )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check the size of our inverted index..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "147"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ix.doc_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
